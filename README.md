### LLM Evaluation Methods

1. Human Evaluation: Ask humans to evaluate the output (slow)
2. Use predefined metrics: eg. BLEU, ROGUE etc.
3. Use AI model to evaluate AI model (eg. GPT-4 evaluates Llama3)

Note: LLM Evaluators Recognize and Favour Their Own Generations

### LLM Evaluation Tools

- RAGAS: Evaluation for RAGS pipelines
- DeepEval: The LLM Evaluation Framework

### Metrics

- Hallucinations: looks for non-factual or conflicting information
- Faithfulness: measures how well the answer matches the context given
- Answer Relevance: checks how closely the answer matches the question


